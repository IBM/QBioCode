

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>qbiocode.learning.compute_mlp module &mdash; qbiocode 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=d45e8c67"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            qbiocode
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Prerequisite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Gallery</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview of qbiocode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Applications</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apps/profiler.html">Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apps/sage.html">Sage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_overview.html">API Overview</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">qbiocode</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">qbiocode.learning.compute_mlp module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/qbiocode.learning.compute_mlp.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-qbiocode.learning.compute_mlp">
<span id="qbiocode-learning-compute-mlp-module"></span><h1>qbiocode.learning.compute_mlp module<a class="headerlink" href="#module-qbiocode.learning.compute_mlp" title="Link to this heading"></a></h1>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h2>
<p>Functions:</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#qbiocode.learning.compute_mlp.compute_mlp" title="qbiocode.learning.compute_mlp.compute_mlp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_mlp</span></code></a></p></td>
<td><p>This function generates a model using a Multi-layer Perceptron (mlp), a neural network, method as implemented in scikit-learn (<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html</a>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#qbiocode.learning.compute_mlp.compute_mlp_opt" title="qbiocode.learning.compute_mlp.compute_mlp_opt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_mlp_opt</span></code></a></p></td>
<td><p>This function also generates a model using a Multi-layer Perceptron (mlp), a neural network, as implemented in scikit-learn (<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html</a>).</p></td>
</tr>
</tbody>
</table>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="qbiocode.learning.compute_mlp.compute_mlp">
<span class="sig-name descname"><span class="pre">compute_mlp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Multi-layer</span> <span class="pre">Perceptron'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_layer_sizes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(100,)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'adam'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'constant'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">power_t</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nesterovs_momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta_1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter_no_change</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">15000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/qbiocode/learning/compute_mlp.html#compute_mlp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#qbiocode.learning.compute_mlp.compute_mlp" title="Link to this definition"></a></dt>
<dd><p>This function generates a model using a Multi-layer Perceptron (mlp), a neural network, method as implemented in scikit-learn
(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html</a>). It takes in parameter
arguments specified in the config.yaml file, but will use the default parameters specified above if none are passed.
The model is trained on the training dataset and validated on the test dataset. The function returns the evaluation of the model
on the test dataset, including accuracy, AUC, F1 score, and the time taken to train and validate the model.
This function is designed to be used in a supervised learning context, where the goal is to classify data points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_train</strong> (<em>numpy.ndarray</em>) – Training features.</p></li>
<li><p><strong>X_test</strong> (<em>numpy.ndarray</em>) – Test features.</p></li>
<li><p><strong>y_train</strong> (<em>numpy.ndarray</em>) – Training labels.</p></li>
<li><p><strong>y_test</strong> (<em>numpy.ndarray</em>) – Test labels.</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – Additional arguments, such as config parameters.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – If True, prints additional information during execution.</p></li>
<li><p><strong>model</strong> (<em>str</em>) – Name of the model being used.</p></li>
<li><p><strong>data_key</strong> (<em>str</em>) – Key for the dataset, if applicable.</p></li>
<li><p><strong>hidden_layer_sizes</strong> (<em>tuple</em>) – The ith element represents the number of neurons in the ith hidden layer.</p></li>
<li><p><strong>activation</strong> (<em>str</em>) – Activation function for the hidden layer.</p></li>
<li><p><strong>solver</strong> (<em>str</em>) – The solver for weight optimization.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – L2 penalty (regularization term) parameter.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em> or </em><em>str</em>) – Size of minibatches for stochastic optimizers.</p></li>
<li><p><strong>learning_rate</strong> (<em>str</em>) – Learning rate schedule for weight updates.</p></li>
<li><p><strong>learning_rate_init</strong> (<em>float</em>) – Initial learning rate used.</p></li>
<li><p><strong>power_t</strong> (<em>float</em>) – The exponent for inverse scaling learning rate.</p></li>
<li><p><strong>max_iter</strong> (<em>int</em>) – Maximum number of iterations.</p></li>
<li><p><strong>shuffle</strong> (<em>bool</em>) – Whether to shuffle samples in each iteration.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>None</em>) – Random seed for reproducibility.</p></li>
<li><p><strong>tol</strong> (<em>float</em>) – Tolerance for stopping criteria.</p></li>
<li><p><strong>warm_start</strong> (<em>bool</em>) – If True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution.</p></li>
<li><p><strong>momentum</strong> (<em>float</em>) – Momentum for gradient descent update.</p></li>
<li><p><strong>nesterovs_momentum</strong> (<em>bool</em>) – Whether to use Nesterov’s momentum or not.</p></li>
<li><p><strong>early_stopping</strong> (<em>bool</em>) – Whether to use early stopping to terminate training when validation score is not improving.</p></li>
<li><p><strong>validation_fraction</strong> (<em>float</em>) – Proportion of training data to set aside as validation set for early stopping.</p></li>
<li><p><strong>beta_1</strong> – Parameters for Adam optimizer.</p></li>
<li><p><strong>beta_2</strong> – Parameters for Adam optimizer.</p></li>
<li><p><strong>epsilon</strong> – Parameters for Adam optimizer.</p></li>
<li><p><strong>n_iter_no_change</strong> – Number of iterations with no improvement after which training will be stopped.</p></li>
<li><p><strong>max_fun</strong> – Maximum number of function evaluations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A dictionary containing the evaluation metrics of the model on the test dataset, including accuracy, AUC, F1 score,</dt><dd><p>and the time taken to train and validate the model, along with the model parameters.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>modeleval (dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="qbiocode.learning.compute_mlp.compute_mlp_opt">
<span class="sig-name descname"><span class="pre">compute_mlp_opt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Multi-layer</span> <span class="pre">Perceptron'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_layer_sizes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/qbiocode/learning/compute_mlp.html#compute_mlp_opt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#qbiocode.learning.compute_mlp.compute_mlp_opt" title="Link to this definition"></a></dt>
<dd><p>This function also generates a model using a Multi-layer Perceptron (mlp), a neural network, as implemented in scikit-learn
(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html</a>). The difference here is that
this function runs a grid search. The range of the grid search for each parameter is specified in the config.yaml file. The
combination of parameters that led to the best performance is saved and returned as best_params, which can then be used on similar
datasets, without having to run the grid search.  The model is trained on the training dataset and validated on the test dataset. The function returns the evaluation of the model
on the test dataset, including accuracy, AUC, F1 score, and the time taken to train and validate the model across the grid search.
This function is designed to be used in a supervised learning context, where the goal is to classify data points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_train</strong> (<em>numpy.ndarray</em>) – Training features.</p></li>
<li><p><strong>X_test</strong> (<em>numpy.ndarray</em>) – Test features.</p></li>
<li><p><strong>y_train</strong> (<em>numpy.ndarray</em>) – Training labels.</p></li>
<li><p><strong>y_test</strong> (<em>numpy.ndarray</em>) – Test labels.</p></li>
<li><p><strong>args</strong> (<em>dict</em>) – Additional arguments, such as config parameters.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – If True, prints additional information during execution.</p></li>
<li><p><strong>cv</strong> (<em>int</em>) – Number of cross-validation folds.</p></li>
<li><p><strong>model</strong> (<em>str</em>) – Name of the model being used.</p></li>
<li><p><strong>hidden_layer_sizes</strong> (<em>tuple</em><em> or </em><em>list</em>) – The ith element represents the number of neurons in the ith hidden layer.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em> or </em><em>list</em>) – Activation function for the hidden layer.</p></li>
<li><p><strong>max_iter</strong> (<em>int</em><em> or </em><em>list</em>) – Maximum number of iterations.</p></li>
<li><p><strong>solver</strong> (<em>str</em><em> or </em><em>list</em>) – The solver for weight optimization.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em> or </em><em>list</em>) – L2 penalty (regularization term) parameter.</p></li>
<li><p><strong>learning_rate</strong> (<em>str</em><em> or </em><em>list</em>) – Learning rate schedule for weight updates.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A dictionary containing the evaluation metrics of the model on the test dataset, including accuracy, AUC, F1 score,</dt><dd><p>and the time taken to train and validate the model, along with the best parameters found during grid search.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>modeleval (dict)</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025 IBM Research, Bryan Raubenolt, Aritra Bose, Kahn Rhrissorrakrai, Filippo Utro, Akhil Mohan, Daniel Blankenberg, Laxmi Parida.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>