{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin generation of yamls for manual grid search using QML methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Cell below sets the list of parameters to iterate over and generate combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QMethods\n",
    "qmethods = [ 'qnn', 'vqc', 'qsvc' ]\n",
    "reps = [1,2]\n",
    "optimizers = ['COBYLA', 'SPSA' ]\n",
    "entanglements = ['linear', 'full' ]\n",
    "feature_maps = ['Z', 'ZZ']\n",
    "ansatz_types = ['amp', 'esu2']\n",
    "n_components = [5,10]\n",
    "Cs =  [0.1, 1, 10]\n",
    "max_iters = [100,500]\n",
    "embeddings = ['pca', 'nmf', 'none']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's set the paths for input and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "dir_home= re.sub( 'qml4omics.*', 'qml4omics', os.getcwd() )\n",
    "dir_config = os.path.join( dir_home, 'configs' )\n",
    "file_template_config = os.path.join( dir_config, 'config.yaml' )\n",
    "dir_config_new = os.path.join( dir_config, 'configs_qml_gridsearch' )\n",
    "used_data_files = os.path.join( dir_config_new, 'used_data_files.csv' )\n",
    "\n",
    "\n",
    "if not os.path.exists(dir_config_new):\n",
    "    os.mkdir(dir_config_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below will now generate dataframes with unique combinations of QML method parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     method  reps local_optimizer entanglement feature_map ansatz_type  \\\n",
      "0       qnn     1          COBYLA       linear           Z         amp   \n",
      "1       qnn     1          COBYLA       linear           Z         amp   \n",
      "2       qnn     1          COBYLA       linear           Z         amp   \n",
      "3       qnn     1          COBYLA       linear           Z         amp   \n",
      "4       qnn     1          COBYLA       linear           Z         amp   \n",
      "...     ...   ...             ...          ...         ...         ...   \n",
      "2527   qsvc     1          COBYLA         full          ZZ         amp   \n",
      "2528   qsvc     1          COBYLA         full          ZZ         amp   \n",
      "2532   qsvc     1          COBYLA         full          ZZ         amp   \n",
      "2533   qsvc     1          COBYLA         full          ZZ         amp   \n",
      "2534   qsvc     1          COBYLA         full          ZZ         amp   \n",
      "\n",
      "      n_components     C  max_iter embedding  \n",
      "0                5   1.0       100       pca  \n",
      "1                5   1.0       100       nmf  \n",
      "2                5   1.0       100      none  \n",
      "3                5   1.0       500       pca  \n",
      "4                5   1.0       500       nmf  \n",
      "...            ...   ...       ...       ...  \n",
      "2527             5   1.0       100       nmf  \n",
      "2528             5   1.0       100      none  \n",
      "2532             5  10.0       100       pca  \n",
      "2533             5  10.0       100       nmf  \n",
      "2534             5  10.0       100      none  \n",
      "\n",
      "[324 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#############    \n",
    "import itertools\n",
    "p = [qmethods, reps, optimizers, entanglements, feature_maps, ansatz_types, n_components, Cs, max_iters, embeddings]\n",
    "\n",
    "p_c = pd.DataFrame(list(itertools.product(*p)),\n",
    "                   columns=[\n",
    "                       'method',\n",
    "                       'reps',\n",
    "                       'local_optimizer',\n",
    "                       'entanglement',\n",
    "                       'feature_map',\n",
    "                       'ansatz_type',\n",
    "                       'n_components',\n",
    "                       'C',\n",
    "                       'max_iter',\n",
    "                       'embedding'\n",
    "                   ])\n",
    "p_c.loc[ p_c['method'].isin( ['qnn','vqc']), 'C' ] = 1\n",
    "p_c.loc[ p_c['method'].isin( ['qsvc']), 'ansatz_type' ] = 'amp'\n",
    "p_c.loc[ p_c['method'].isin( ['qsvc']), 'max_iter' ] = 100\n",
    "p_c.loc[ p_c['method'].isin( ['qsvc']), 'local_optimizer' ] = 'COBYLA'\n",
    "\n",
    "p_c = p_c.drop_duplicates()\n",
    "p_c = p_c[~((p_c['n_components'] >= 10) & (p_c['max_iter'] < 500))]\n",
    "p_c = p_c[~((p_c['reps'] > 1) & (p_c['n_components'] <= 10))] # for small feature space, you may not need more than 1 layer of the ansatz\n",
    "print(p_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataframe generated previously will now be used to populate the individual config.yaml files, for each dataset you want to include.\n",
    "## These yamls files can then be iteratively used with the main function (qml4omics-profiler.py), using the HPC slurm script provided in slurm_scripts/job_submission_forloop.sh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to Series, length must be 1: given 4",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/var/folders/b8/mhwk24h93j30s2r57fb_4q3wsywh_6/T/ipykernel_64643/3576618105.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Use all files\u001b[39;00m\n\u001b[32m     23\u001b[39m     files = list(np.random.choice( files, int(len(files)*\u001b[32m1\u001b[39m)))\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# Or use a random sample of 10% of files\u001b[39;00m\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# files = list(np.random.choice( files, int(len(files)*1)))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     used_files = used_files + files\n\u001b[32m     27\u001b[39m     p_c_t = p_c.copy()\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[33m'moons'\u001b[39m \u001b[38;5;28;01min\u001b[39;00m dir_data) | (\u001b[33m'circles'\u001b[39m \u001b[38;5;28;01min\u001b[39;00m dir_data):\n\u001b[32m     29\u001b[39m         p_c_t = p_c_t[ p_c_t[\u001b[33m'embedding'\u001b[39m] == \u001b[33m'none'\u001b[39m ]\n",
      "\u001b[32m~/opt/miniconda3/envs/qml4omics-testenv/lib/python3.11/site-packages/pandas/core/ops/common.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m NotImplemented\n\u001b[32m     73\u001b[39m \n\u001b[32m     74\u001b[39m         other = item_from_zerodim(other)\n\u001b[32m     75\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m method(self, other)\n",
      "\u001b[32m~/opt/miniconda3/envs/qml4omics-testenv/lib/python3.11/site-packages/pandas/core/arraylike.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    182\u001b[39m         deer      NaN     NaN\n\u001b[32m    183\u001b[39m         elk       \u001b[32m1.7\u001b[39m     NaN\n\u001b[32m    184\u001b[39m         moose     \u001b[32m3.0\u001b[39m     NaN\n\u001b[32m    185\u001b[39m         \"\"\"\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._arith_method(other, operator.add)\n",
      "\u001b[32m~/opt/miniconda3/envs/qml4omics-testenv/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   7906\u001b[39m \n\u001b[32m   7907\u001b[39m         axis: Literal[\u001b[32m1\u001b[39m] = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[32m   7908\u001b[39m         other = ops.maybe_prepare_scalar_for_op(other, (self.shape[axis],))\n\u001b[32m   7909\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7910\u001b[39m         self, other = self._align_for_op(other, axis, flex=\u001b[38;5;28;01mTrue\u001b[39;00m, level=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   7911\u001b[39m \n\u001b[32m   7912\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(all=\u001b[33m\"ignore\"\u001b[39m):\n\u001b[32m   7913\u001b[39m             new_data = self._dispatch_frame_op(other, op, axis=axis)\n",
      "\u001b[32m~/opt/miniconda3/envs/qml4omics-testenv/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other, axis, flex, level)\u001b[39m\n\u001b[32m   8183\u001b[39m                 raise ValueError(\n\u001b[32m   8184\u001b[39m                     \u001b[33mf\"Unable to coerce list of {type(right[0])} to Series/DataFrame\"\u001b[39m\n\u001b[32m   8185\u001b[39m                 )\n\u001b[32m   8186\u001b[39m             \u001b[38;5;66;03m# GH#17901\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m8187\u001b[39m             right = to_series(right)\n\u001b[32m   8188\u001b[39m \n\u001b[32m   8189\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m flex \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m isinstance(right, DataFrame):\n\u001b[32m   8190\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m left._indexed_same(right):\n",
      "\u001b[32m~/opt/miniconda3/envs/qml4omics-testenv/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(right)\u001b[39m\n\u001b[32m   8129\u001b[39m                     )\n\u001b[32m   8130\u001b[39m                 right = left._constructor_sliced(right, index=left.index, dtype=dtype)\n\u001b[32m   8131\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   8132\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m len(left.columns) != len(right):\n\u001b[32m-> \u001b[39m\u001b[32m8133\u001b[39m                     raise ValueError(\n\u001b[32m   8134\u001b[39m                         msg.format(req_len=len(left.columns), given_len=len(right))\n\u001b[32m   8135\u001b[39m                     )\n\u001b[32m   8136\u001b[39m                 right = left._constructor_sliced(right, index=left.columns, dtype=dtype)\n",
      "\u001b[31mValueError\u001b[39m: Unable to coerce to Series, length must be 1: given 4"
     ]
    }
   ],
   "source": [
    "############\n",
    "idx = 1 \n",
    "cfg_orig = yaml.safe_load( open( file_template_config, 'r+' ) )\n",
    "\n",
    "if os.path.exists( used_data_files ):\n",
    "    used_files = pd.read_csv(used_data_files)\n",
    "else:\n",
    "    used_files = []\n",
    "\n",
    "# Data Files\n",
    "for dir_data in [\n",
    "    #os.path.join( dir_home, 'data', 'tutorial_test_data', 'higher_dim_datasets'),\n",
    "    os.path.join( dir_home, 'data', 'tutorial_test_data', 'lower_dim_datasets')\n",
    "\n",
    "]:\n",
    "    files = [ fl for fl in os.listdir(dir_data) if 'csv' in fl ]\n",
    "    files.sort()\n",
    "    # remove files previously used    \n",
    "    files = list(set(files).difference(set(used_files)) )\n",
    "\n",
    "    \n",
    "    # Use all files\n",
    "    files = list(np.random.choice( files, int(len(files)*1)))\n",
    "    # Or use a random sample of 10% of files\n",
    "    # files = list(np.random.choice( files, int(len(files)*1)))\n",
    "    used_files = used_files + files\n",
    "    p_c_t = p_c.copy()\n",
    "    if ('moons' in dir_data) | ('circles' in dir_data):\n",
    "        p_c_t = p_c_t[ p_c_t['embedding'] == 'none' ]\n",
    "    else:\n",
    "        p_c_t = p_c_t[ p_c_t['embedding'] != 'none' ]\n",
    "\n",
    "    count = 1\n",
    "    for ix, row in p_c_t.iterrows():\n",
    "        for fl in files:\n",
    "            file_yaml = os.path.join( dir_config_new, 'exp_' + str(idx) + '.yaml')\n",
    "            key = row['method'] + '_' + re.sub( '.csv', '', fl )\n",
    "            cfg = cfg_orig.copy()\n",
    "            cfg['yaml'] = file_yaml\n",
    "            cfg['model'] = [row['method']]\n",
    "            cfg['file_dataset'] = str(fl)\n",
    "            cfg['folder_path'] = re.sub( 'data/', '', dir_data )\n",
    "            cfg['hydra']['run']['dir'] = os.path.join( 'results', 'qmlgridsearch_' + key )\n",
    "            \n",
    "            ###\n",
    "            # This block looks at the input dataset and ensures the embedding method placed in the yaml\n",
    "            # is 'none' if n_components is equal to or greater than the original number of features \n",
    "            # in the input data set.  This should help avoid redundant yaml files, since using either of \n",
    "            # the embedding methods (pca, nmf) in this scenario is essentially the same as choosing 'none', thus\n",
    "            # leading to the same experiment being run, even though the yaml file might be different. \n",
    "            fl_df=pd.read_csv(dir_data+'/'+fl)\n",
    "            orig_features = fl_df.shape[1]-1\n",
    "            if row['n_components'] >= orig_features:\n",
    "                #print(orig_features, row['n_components'])\n",
    "                cfg['embeddings'] = [str('none')]\n",
    "                count += 1\n",
    "            else:\n",
    "                cfg['embeddings'] = [row['embedding']]\n",
    "            \n",
    "            cfg['n_components'] = row['n_components']\n",
    "            ###\n",
    "            \n",
    "            cfg[row['method']+'_args']['reps'] = row['reps']\n",
    "            cfg[row['method']+'_args']['entanglement'] = row['entanglement']\n",
    "            cfg[row['method']+'_args']['encoding'] = row['feature_map']\n",
    "            \n",
    "            if row['method'] != 'qsvc':\n",
    "                cfg[row['method']+'_args']['ansatz_type'] = row['ansatz_type']\n",
    "                cfg[row['method']+'_args']['maxiter'] = row['max_iter']\n",
    "            else:\n",
    "                cfg[row['method']+'_args']['C'] = row['C']\n",
    "                cfg[row['method']+'_args']['local_optimizer'] = row['local_optimizer']\n",
    "                            \n",
    "            yaml.dump( cfg, open( file_yaml, 'w'), default_flow_style= False )   \n",
    "            idx += 1\n",
    "\n",
    "pd.Series(used_files).to_csv( used_data_files, index = False)\n",
    "\n",
    "idx-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End generation of yamls for manual grid search using QML methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qml4omics-testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
