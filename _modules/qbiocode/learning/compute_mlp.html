

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>qbiocode.learning.compute_mlp &mdash; qbiocode 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=d45e8c67"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            qbiocode
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Prerequisite</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Gallery</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../overview.html">Overview of qbiocode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial.html">Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Applications</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../apps/profiler.html">Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../apps/sage.html">Sage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api_overview.html">API Overview</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">qbiocode</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">qbiocode.learning.compute_mlp</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for qbiocode.learning.compute_mlp</h1><div class="highlight"><pre>
<span></span><span class="c1"># ====== Base class imports ======</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># ====== Scikit-learn imports ======</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neural_network</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.multiclass</span><span class="w"> </span><span class="kn">import</span> <span class="n">OneVsOneClassifier</span><span class="p">,</span> <span class="n">OneVsRestClassifier</span>

<span class="c1"># ====== Additional local imports ======</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">qbiocode.evaluation.model_evaluation</span><span class="w"> </span><span class="kn">import</span> <span class="n">modeleval</span>

<span class="c1"># ====== Begin functions ======</span>

<div class="viewcode-block" id="compute_mlp">
<a class="viewcode-back" href="../../../api/qbiocode.learning.compute_mlp.html#qbiocode.learning.compute_mlp.compute_mlp">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_mlp</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;Multi-layer Perceptron&#39;</span><span class="p">,</span> <span class="n">data_key</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
                <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> 
                <span class="n">learning_rate</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">power_t</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> 
                <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">n_iter_no_change</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_fun</span><span class="o">=</span><span class="mi">15000</span><span class="p">):</span>
<span class="w">        </span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function generates a model using a Multi-layer Perceptron (mlp), a neural network, method as implemented in scikit-learn </span>
<span class="sd">        (https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html). It takes in parameter</span>
<span class="sd">        arguments specified in the config.yaml file, but will use the default parameters specified above if none are passed. </span>
<span class="sd">        The model is trained on the training dataset and validated on the test dataset. The function returns the evaluation of the model </span>
<span class="sd">        on the test dataset, including accuracy, AUC, F1 score, and the time taken to train and validate the model.</span>
<span class="sd">        This function is designed to be used in a supervised learning context, where the goal is to classify data points.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_train (numpy.ndarray): Training features.</span>
<span class="sd">            X_test (numpy.ndarray): Test features.</span>
<span class="sd">            y_train (numpy.ndarray): Training labels.</span>
<span class="sd">            y_test (numpy.ndarray): Test labels.</span>
<span class="sd">            args (dict): Additional arguments, such as config parameters.</span>
<span class="sd">            verbose (bool): If True, prints additional information during execution.</span>
<span class="sd">            model (str): Name of the model being used.</span>
<span class="sd">            data_key (str): Key for the dataset, if applicable.</span>
<span class="sd">            hidden_layer_sizes (tuple): The ith element represents the number of neurons in the ith hidden layer.</span>
<span class="sd">            activation (str): Activation function for the hidden layer.</span>
<span class="sd">            solver (str): The solver for weight optimization.</span>
<span class="sd">            alpha (float): L2 penalty (regularization term) parameter.</span>
<span class="sd">            batch_size (int or str): Size of minibatches for stochastic optimizers.</span>
<span class="sd">            learning_rate (str): Learning rate schedule for weight updates.</span>
<span class="sd">            learning_rate_init (float): Initial learning rate used.</span>
<span class="sd">            power_t (float): The exponent for inverse scaling learning rate.</span>
<span class="sd">            max_iter (int): Maximum number of iterations.</span>
<span class="sd">            shuffle (bool): Whether to shuffle samples in each iteration.</span>
<span class="sd">            random_state (int or None): Random seed for reproducibility.</span>
<span class="sd">            tol (float): Tolerance for stopping criteria.</span>
<span class="sd">            warm_start (bool): If True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution.</span>
<span class="sd">            momentum (float): Momentum for gradient descent update.</span>
<span class="sd">            nesterovs_momentum (bool): Whether to use Nesterov&#39;s momentum or not.</span>
<span class="sd">            early_stopping (bool): Whether to use early stopping to terminate training when validation score is not improving.</span>
<span class="sd">            validation_fraction (float): Proportion of training data to set aside as validation set for early stopping.</span>
<span class="sd">            beta_1, beta_2, epsilon: Parameters for Adam optimizer.</span>
<span class="sd">            n_iter_no_change: Number of iterations with no improvement after which training will be stopped.</span>
<span class="sd">            max_fun: Maximum number of function evaluations.</span>

<span class="sd">        Returns:</span>
<span class="sd">                modeleval (dict): A dictionary containing the evaluation metrics of the model on the test dataset, including accuracy, AUC, F1 score,</span>
<span class="sd">                          and the time taken to train and validate the model, along with the model parameters.   </span>
<span class="sd">    &quot;&quot;&quot;</span>  
    
    <span class="n">beg_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">mlp</span> <span class="o">=</span> <span class="n">OneVsOneClassifier</span><span class="p">(</span><span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="n">hidden_layer_sizes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> 
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">learning_rate_init</span><span class="o">=</span><span class="n">learning_rate_init</span><span class="p">,</span> 
                                           <span class="n">power_t</span><span class="o">=</span><span class="n">power_t</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> 
                                           <span class="n">warm_start</span><span class="o">=</span><span class="n">warm_start</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">,</span> <span class="n">nesterovs_momentum</span><span class="o">=</span><span class="n">nesterovs_momentum</span><span class="p">,</span> 
                                           <span class="n">early_stopping</span><span class="o">=</span><span class="n">early_stopping</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="n">validation_fraction</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="n">beta_1</span><span class="p">,</span> 
                                           <span class="n">beta_2</span><span class="o">=</span><span class="n">beta_2</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">n_iter_no_change</span><span class="o">=</span><span class="n">n_iter_no_change</span><span class="p">,</span> <span class="n">max_fun</span><span class="o">=</span><span class="n">max_fun</span><span class="p">))</span>
    <span class="c1"># Fit the training datset</span>
    <span class="n">model_fit</span> <span class="o">=</span> <span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">model_params</span> <span class="o">=</span> <span class="n">model_fit</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
    <span class="c1"># Validate the model in test dataset and calculate accuracy</span>
    <span class="n">y_predicted</span> <span class="o">=</span> <span class="n">mlp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> 
    <span class="k">return</span><span class="p">(</span><span class="n">modeleval</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">,</span> <span class="n">beg_time</span><span class="p">,</span> <span class="n">model_params</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">))</span></div>


<div class="viewcode-block" id="compute_mlp_opt">
<a class="viewcode-back" href="../../../api/qbiocode.learning.compute_mlp.html#qbiocode.learning.compute_mlp.compute_mlp_opt">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_mlp_opt</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;Multi-layer Perceptron&#39;</span><span class="p">,</span>
                    <span class="n">hidden_layer_sizes</span><span class="o">=</span> <span class="p">[],</span> <span class="n">activation</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">max_iter</span><span class="o">=</span> <span class="p">[],</span>
                    <span class="n">solver</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">learning_rate</span><span class="o">=</span> <span class="p">[]):</span>
<span class="w">        </span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function also generates a model using a Multi-layer Perceptron (mlp), a neural network, as implemented in scikit-learn </span>
<span class="sd">        (https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html). The difference here is that</span>
<span class="sd">        this function runs a grid search. The range of the grid search for each parameter is specified in the config.yaml file. The</span>
<span class="sd">        combination of parameters that led to the best performance is saved and returned as best_params, which can then be used on similar</span>
<span class="sd">        datasets, without having to run the grid search.  The model is trained on the training dataset and validated on the test dataset. The function returns the evaluation of the model </span>
<span class="sd">        on the test dataset, including accuracy, AUC, F1 score, and the time taken to train and validate the model across the grid search.</span>
<span class="sd">        This function is designed to be used in a supervised learning context, where the goal is to classify data points.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">                X_train (numpy.ndarray): Training features.</span>
<span class="sd">                X_test (numpy.ndarray): Test features.</span>
<span class="sd">                y_train (numpy.ndarray): Training labels.</span>
<span class="sd">                y_test (numpy.ndarray): Test labels.</span>
<span class="sd">                args (dict): Additional arguments, such as config parameters.</span>
<span class="sd">                verbose (bool): If True, prints additional information during execution.</span>
<span class="sd">                cv (int): Number of cross-validation folds.</span>
<span class="sd">                model (str): Name of the model being used.</span>
<span class="sd">                hidden_layer_sizes (tuple or list): The ith element represents the number of neurons in the ith hidden layer.</span>
<span class="sd">                activation (str or list): Activation function for the hidden layer.</span>
<span class="sd">                max_iter (int or list): Maximum number of iterations.</span>
<span class="sd">                solver (str or list): The solver for weight optimization.</span>
<span class="sd">                alpha (float or list): L2 penalty (regularization term) parameter.</span>
<span class="sd">                learning_rate (str or list): Learning rate schedule for weight updates.</span>
<span class="sd">        Returns:</span>
<span class="sd">                modeleval (dict): A dictionary containing the evaluation metrics of the model on the test dataset, including accuracy, AUC, F1 score,</span>
<span class="sd">                          and the time taken to train and validate the model, along with the best parameters found during grid search.</span>
<span class="sd">    &quot;&quot;&quot;</span>   
    
    <span class="n">beg_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;hidden_layer_sizes&#39;</span><span class="p">:</span> <span class="n">hidden_layer_sizes</span><span class="p">,</span>
            <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="n">activation</span><span class="p">,</span> 
            <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="n">max_iter</span><span class="p">,</span>
            <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="n">solver</span><span class="p">,</span>
            <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">alpha</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
            <span class="p">}</span>
    
    <span class="c1"># Pemlporm Grid Search to find the best parameters</span>
    <span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">MLPClassifier</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
    <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Get the best parameters and use them to create the final model</span>
    <span class="n">best_params</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
    <span class="n">best_mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
    <span class="n">best_mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Make predictions and calculate accuracy</span>
    <span class="n">y_predicted</span> <span class="o">=</span> <span class="n">best_mlp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="k">return</span><span class="p">(</span><span class="n">modeleval</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">,</span> <span class="n">beg_time</span><span class="p">,</span> <span class="n">best_params</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">))</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025 IBM Research, Bryan Raubenolt, Aritra Bose, Kahn Rhrissorrakrai, Filippo Utro, Akhil Mohan, Daniel Blankenberg, Laxmi Parida.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>