{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-cell RNA data on Minimal Residual disease for melanoma!\n",
    "![MRD](mrd.png \"Minimal residual Disease for melanoma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Control\n",
    "![qc](mrd1.png \"Quality Control for MRD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate lower-dimensional embeddings\n",
    "\n",
    "We will perform dimensionality reduction and generate lower-dimensional embeddings of the single-cell RNAseq data using two methods:\n",
    "* PCA (https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "* Neural Networks (https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "sns.set_style('dark')\n",
    "\n",
    "# ====== Scikit-learn imports ======\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    roc_curve,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "## ====== Torch imports ======\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from lightning.pytorch.utilities.types import OptimizerLRScheduler\n",
    "import torch.utils.data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import lightning, lightning.pytorch.loggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369, 2002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3855306/715312502.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels_filtered['Labels'] = [x.split(' ')[1] for x in labels_filtered['Labels']]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/GSE116237_forQ.csv\")\n",
    "print(df.shape)\n",
    "labels = pd.read_csv(\"../data/GSE116237 filtered labels.csv\")\n",
    "labels.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "labels.columns = ['Cells', 'Labels']\n",
    "labels_filtered = labels[labels['Cells'].isin(list(df['Cells']))]\n",
    "labels_filtered['Labels'] = [x.split(' ')[1] for x in labels_filtered['Labels']]\n",
    "df = pd.merge(df, labels_filtered, on='Cells', how='inner')\n",
    "df['Labels'] = df['Labels'].map({'T0': 0, 'phase2': 1})\n",
    "y = np.array(df['Labels'])\n",
    "X = df[df.columns[1:-1]].values\n",
    "\n",
    "num_samples = X.shape[0]\n",
    "num_feats = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_working, X_held_out, y_working, y_held_out = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    train_size=0.8,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data dimensions:  (295, 2001)\n",
      "Embedded train dimensions:  (295, 10)\n",
      "Testing data dimensions:  (74, 2001)\n",
      "Embedded test dimensions:  (74, 10)\n"
     ]
    }
   ],
   "source": [
    "output_dim = 10 \n",
    "pca = PCA(n_components=output_dim)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_working)\n",
    "embedding_train = pca.fit_transform(X_train_scaled)\n",
    "X_test_scaled = scaler.fit_transform(X_held_out)\n",
    "embedding_test = pca.fit_transform(X_test_scaled)\n",
    "print(\"Training data dimensions: \", X_working.shape)\n",
    "print(\"Embedded train dimensions: \", embedding_train.shape)\n",
    "print(\"Testing data dimensions: \", X_held_out.shape)\n",
    "print(\"Embedded test dimensions: \", embedding_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network in Pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = torch.nn.Sequential(\n",
    "            nn.Linear(num_feats,256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256,64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64,32), \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32,16), \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16,output_dim),\n",
    "            nn.LeakyReLU(), \n",
    "            ) \n",
    "\n",
    "classifier = torch.nn.Sequential(\n",
    "            nn.Linear(output_dim,1),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "class BinaryClassifierModel(lightning.LightningModule):\n",
    "    def __init__(self, embedder, classifier, input_dim,learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedder = embedder\n",
    "        self.classifier = classifier\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_fun = nn.BCELoss()\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data, batch_size=32)  # No shuffling for validation\n",
    "    \n",
    "    def forward(self, X): \n",
    "        x = self.embedder(X)\n",
    "        x = self.classifier(x) \n",
    "        return x \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.unsqueeze(1)\n",
    "        y_float = y.float()\n",
    "        x_embedder = self.embedder(x)\n",
    "        y_hat = self.classifier(x_embedder)\n",
    "        #y_hat = torch.argmax(y_hat, dim=1)\n",
    "        loss = self.loss_fun(y_hat, y_float)\n",
    "        self.log(\"train_loss\", loss, \n",
    "                prog_bar=True, \n",
    "                logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.unsqueeze(1)\n",
    "        y_float = y.float()\n",
    "        x_embedder = self.embedder(x)\n",
    "        y_hat = self.classifier(x_embedder)\n",
    "        val_loss = self.loss_fun(y_hat, y_float)\n",
    "        f1score = f1_score(y_hat, y)\n",
    "        print(f1score)\n",
    "        #print(val_loss)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=False, logger=True)  # Log on epoch end\n",
    "        return val_loss\n",
    "\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.classifier.parameters(), lr=self.learning_rate)\n",
    "    \n",
    "def prepare_data(X_train, y_train, X_val, y_val):\n",
    "    # Assuming X and y are NumPy arrays\n",
    "\n",
    "    train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32), \n",
    "                        torch.tensor(y_train, dtype=torch.float32))\n",
    "    val_data = TensorDataset(torch.tensor(X_val, dtype=torch.float32), \n",
    "                        torch.tensor(y_val, dtype=torch.float32))\n",
    "    \n",
    "    return train_data, val_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the embeddings using the network and get lower dimension embeddings in the form of matrices for downstream QML tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | embedder   | Sequential | 531 K \n",
      "1 | classifier | Sequential | 11    \n",
      "2 | loss_fun   | BCELoss    | 0     \n",
      "------------------------------------------\n",
      "531 K     Trainable params\n",
      "0         Non-trainable params\n",
      "531 K     Total params\n",
      "2.127     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/boseukb/conda/Q/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/boseukb/conda/Q/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/dccstor/boseukb/conda/Q/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  22%|██▏       | 2/9 [00:00<00:00, 35.96it/s, v_num=3, train_loss=34.40]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 9/9 [00:00<00:00, 36.92it/s, v_num=3, train_loss=66.70]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.95it/s]\n",
      "Epoch 1: 100%|██████████| 9/9 [00:00<00:00, 37.86it/s, v_num=3, train_loss=33.30]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.77it/s]\n",
      "Epoch 2: 100%|██████████| 9/9 [00:00<00:00, 38.14it/s, v_num=3, train_loss=77.80]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.23it/s]\n",
      "Epoch 3: 100%|██████████| 9/9 [00:00<00:00, 37.39it/s, v_num=3, train_loss=55.60]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.80it/s]\n",
      "Epoch 4: 100%|██████████| 9/9 [00:00<00:00, 37.91it/s, v_num=3, train_loss=66.70]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.66it/s]\n",
      "Epoch 5: 100%|██████████| 9/9 [00:00<00:00, 37.92it/s, v_num=3, train_loss=22.20]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.34it/s]\n",
      "Epoch 6: 100%|██████████| 9/9 [00:00<00:00, 38.28it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.09it/s]\n",
      "Epoch 7: 100%|██████████| 9/9 [00:00<00:00, 38.37it/s, v_num=3, train_loss=66.70]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.98it/s]\n",
      "Epoch 8: 100%|██████████| 9/9 [00:00<00:00, 38.36it/s, v_num=3, train_loss=33.30]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.38it/s]\n",
      "Epoch 9: 100%|██████████| 9/9 [00:00<00:00, 38.40it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.91it/s]\n",
      "Epoch 10: 100%|██████████| 9/9 [00:00<00:00, 38.01it/s, v_num=3, train_loss=66.70]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.26it/s]\n",
      "Epoch 11: 100%|██████████| 9/9 [00:00<00:00, 37.86it/s, v_num=3, train_loss=66.70]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.53it/s]\n",
      "Epoch 12: 100%|██████████| 9/9 [00:00<00:00, 37.82it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.40it/s]\n",
      "Epoch 13: 100%|██████████| 9/9 [00:00<00:00, 38.02it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.25it/s]\n",
      "Epoch 14: 100%|██████████| 9/9 [00:00<00:00, 37.72it/s, v_num=3, train_loss=66.70]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.23it/s]\n",
      "Epoch 15: 100%|██████████| 9/9 [00:00<00:00, 38.14it/s, v_num=3, train_loss=55.60]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.15it/s]\n",
      "Epoch 16: 100%|██████████| 9/9 [00:00<00:00, 38.19it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.41it/s]\n",
      "Epoch 17: 100%|██████████| 9/9 [00:00<00:00, 37.90it/s, v_num=3, train_loss=33.30]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.90it/s]\n",
      "Epoch 18: 100%|██████████| 9/9 [00:00<00:00, 38.20it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.13it/s]\n",
      "Epoch 19: 100%|██████████| 9/9 [00:00<00:00, 38.21it/s, v_num=3, train_loss=33.30]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.80it/s]\n",
      "Epoch 20: 100%|██████████| 9/9 [00:00<00:00, 38.34it/s, v_num=3, train_loss=22.20]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.92it/s]\n",
      "Epoch 21: 100%|██████████| 9/9 [00:00<00:00, 38.34it/s, v_num=3, train_loss=33.30]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.85it/s]\n",
      "Epoch 22: 100%|██████████| 9/9 [00:00<00:00, 38.07it/s, v_num=3, train_loss=22.20]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.58it/s]\n",
      "Epoch 23: 100%|██████████| 9/9 [00:00<00:00, 38.51it/s, v_num=3, train_loss=22.20]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.30it/s]\n",
      "Epoch 24: 100%|██████████| 9/9 [00:00<00:00, 38.45it/s, v_num=3, train_loss=55.60]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.61it/s]\n",
      "Epoch 25: 100%|██████████| 9/9 [00:00<00:00, 38.15it/s, v_num=3, train_loss=77.80]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.76it/s]\n",
      "Epoch 26: 100%|██████████| 9/9 [00:00<00:00, 38.08it/s, v_num=3, train_loss=66.70]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.70it/s]\n",
      "Epoch 27: 100%|██████████| 9/9 [00:00<00:00, 38.21it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.72it/s]\n",
      "Epoch 28: 100%|██████████| 9/9 [00:00<00:00, 38.46it/s, v_num=3, train_loss=22.20]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.30it/s]\n",
      "Epoch 29: 100%|██████████| 9/9 [00:00<00:00, 38.16it/s, v_num=3, train_loss=22.20]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.27it/s]\n",
      "Epoch 30: 100%|██████████| 9/9 [00:00<00:00, 38.49it/s, v_num=3, train_loss=11.10]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.43it/s]\n",
      "Epoch 31: 100%|██████████| 9/9 [00:00<00:00, 37.76it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.26it/s]\n",
      "Epoch 32: 100%|██████████| 9/9 [00:00<00:00, 38.13it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.49it/s]\n",
      "Epoch 33: 100%|██████████| 9/9 [00:00<00:00, 38.07it/s, v_num=3, train_loss=77.80]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.17it/s]\n",
      "Epoch 34: 100%|██████████| 9/9 [00:00<00:00, 38.26it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.15it/s]\n",
      "Epoch 35: 100%|██████████| 9/9 [00:00<00:00, 37.74it/s, v_num=3, train_loss=55.60]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.62it/s]\n",
      "Epoch 36: 100%|██████████| 9/9 [00:00<00:00, 33.37it/s, v_num=3, train_loss=66.70]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.82it/s]\n",
      "Epoch 37: 100%|██████████| 9/9 [00:00<00:00, 37.49it/s, v_num=3, train_loss=33.30]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.03it/s]\n",
      "Epoch 38: 100%|██████████| 9/9 [00:00<00:00, 37.60it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.87it/s]\n",
      "Epoch 39: 100%|██████████| 9/9 [00:00<00:00, 37.82it/s, v_num=3, train_loss=44.40]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]0.6363636363636364\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.39it/s]\n",
      "Epoch 39: 100%|██████████| 9/9 [00:00<00:00, 33.82it/s, v_num=3, train_loss=44.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=40` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 9/9 [00:00<00:00, 32.82it/s, v_num=3, train_loss=44.40]\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "embeddings_train = []\n",
    "embeddings_test = []\n",
    "num_iter = 1\n",
    "for i in range(num_iter): \n",
    "\n",
    "    X_working, X_held_out, y_working, y_held_out = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        train_size=0.8,\n",
    "                                                        shuffle=True)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_working,\n",
    "                                                        y_working,\n",
    "                                                        train_size=0.9,\n",
    "                                                        shuffle=True)\n",
    "\n",
    "    num_epochs = 40\n",
    "    model = BinaryClassifierModel(embedder, classifier, input_dim=num_feats)\n",
    "    model.train_data, model.val_data = prepare_data(X_train, y_train, X_test, y_test)  # Prepare data for training\n",
    "    logger = lightning.pytorch.loggers.TensorBoardLogger(save_dir=\".\",name=\"original_classifier\")\n",
    "    # Train the model\n",
    "    trainer = lightning.Trainer(max_epochs=num_epochs, \n",
    "                                logger=logger)  # Adjust progress bar refresh rate as needed\n",
    "    trainer.fit(model)\n",
    "    model.eval()\n",
    "    embedded_test = model.embedder(torch.tensor(X_held_out, dtype=torch.float32))\n",
    "    y_pred = model.classifier(embedded_test)\n",
    "    #y_pred = model(torch.tensor(X_held_out, dtype=torch.float32))\n",
    "    y_pred_proba = y_pred.detach().cpu().numpy()\n",
    "    y_pred_class = np.round(y_pred_proba)\n",
    "\n",
    "    f1 = f1_score(y_held_out, y_pred_class)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "    embedded_train = model.embedder(torch.tensor(X_working, dtype=torch.float32)).detach().numpy()\n",
    "    embeddings_train.append(embedded_train)\n",
    "    embeddings_test.append(embedded_test.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"MRD\"\n",
    "fname_train = fname + \"_train_embedding\"\n",
    "np.save(f\"checkpoints/{fname}/{fname_train}\", embedded_train)\n",
    "fname_train_y = fname + \"_train_target\"\n",
    "np.save(f\"checkpoints/{fname}/{fname_train_y}\", y_working)\n",
    "fname_test = fname + \"_test_embedding\"\n",
    "np.save(f\"checkpoints/{fname}/{fname_test}\", embedded_test)\n",
    "fname_test_y = fname + \"_test_target\"\n",
    "np.save(f\"checkpoints/{fname}/{fname_test_y}\", y_held_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
